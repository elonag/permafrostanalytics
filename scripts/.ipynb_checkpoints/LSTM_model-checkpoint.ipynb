{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egusho\\AppData\\Local\\Continuum\\anaconda_3.0\\envs\\deep\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import xgboost as xgb\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = pd.read_csv('../data/MH25_vaisalawxt520prec_2017.csv')\n",
    "wind = pd.read_csv('../data/MH25_vaisalawxt520windpth_2017.csv')\n",
    "temp = pd.read_csv('../data/MH30_temperature_rock_2017.csv')\n",
    "radio = pd.read_csv('../data/MH15_radiometer__conv_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_inner = pd.merge(left= temp, right=prec, left_on='time',right_on='time')\n",
    "temp_inner = pd.merge(left= temp_inner, right=wind, left_on='time',right_on='time')\n",
    "temp_inner = pd.merge(left=temp_inner, right=radio, left_on='time',right_on='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_inner['time'] = pd.to_datetime(temp_inner['time'])\n",
    "temp_inner['season'] = np.round(pd.DatetimeIndex(temp_inner['time']).month/3)\n",
    "del temp_inner['time']\n",
    "\n",
    "temp_inner = temp_inner[['temperature_5cm [°C]', 'temperature_10cm [°C]',\n",
    "       'temperature_20cm [°C]', 'temperature_30cm [°C]',\n",
    "       'temperature_50cm [°C]', 'temperature_100cm [°C]',\n",
    "       'wind_speed_average [km/h]', 'net_radiation [Wm^-2]', 'season']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta_t</th>\n",
       "      <th>temperature_5cm [°C]</th>\n",
       "      <th>temperature_10cm [°C]</th>\n",
       "      <th>temperature_20cm [°C]</th>\n",
       "      <th>temperature_30cm [°C]</th>\n",
       "      <th>temperature_50cm [°C]</th>\n",
       "      <th>temperature_100cm [°C]</th>\n",
       "      <th>wind_speed_average [km/h]</th>\n",
       "      <th>net_radiation [Wm^-2]</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3012</td>\n",
       "      <td>-9.5680</td>\n",
       "      <td>-9.2330</td>\n",
       "      <td>-8.8027</td>\n",
       "      <td>-8.4813</td>\n",
       "      <td>-7.9573</td>\n",
       "      <td>-7.2040</td>\n",
       "      <td>6.6033</td>\n",
       "      <td>-103.3083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3640</td>\n",
       "      <td>-9.6568</td>\n",
       "      <td>-9.3084</td>\n",
       "      <td>-8.8668</td>\n",
       "      <td>-8.5235</td>\n",
       "      <td>-7.9845</td>\n",
       "      <td>-7.2081</td>\n",
       "      <td>7.8323</td>\n",
       "      <td>-102.9365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.4487</td>\n",
       "      <td>-9.7203</td>\n",
       "      <td>-9.3797</td>\n",
       "      <td>-8.9384</td>\n",
       "      <td>-8.5756</td>\n",
       "      <td>-8.0103</td>\n",
       "      <td>-7.2166</td>\n",
       "      <td>8.9094</td>\n",
       "      <td>-101.0145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5037</td>\n",
       "      <td>-9.7547</td>\n",
       "      <td>-9.4270</td>\n",
       "      <td>-8.9953</td>\n",
       "      <td>-8.6287</td>\n",
       "      <td>-8.0473</td>\n",
       "      <td>-7.2120</td>\n",
       "      <td>10.2742</td>\n",
       "      <td>-101.7435</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5427</td>\n",
       "      <td>-9.7981</td>\n",
       "      <td>-9.4790</td>\n",
       "      <td>-9.0455</td>\n",
       "      <td>-8.6703</td>\n",
       "      <td>-8.0768</td>\n",
       "      <td>-7.2187</td>\n",
       "      <td>12.6367</td>\n",
       "      <td>-102.0387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   delta_t  temperature_5cm [°C]  temperature_10cm [°C]  \\\n",
       "1   2.3012               -9.5680                -9.2330   \n",
       "2   2.3640               -9.6568                -9.3084   \n",
       "3   2.4487               -9.7203                -9.3797   \n",
       "4   2.5037               -9.7547                -9.4270   \n",
       "5   2.5427               -9.7981                -9.4790   \n",
       "\n",
       "   temperature_20cm [°C]  temperature_30cm [°C]  temperature_50cm [°C]  \\\n",
       "1                -8.8027                -8.4813                -7.9573   \n",
       "2                -8.8668                -8.5235                -7.9845   \n",
       "3                -8.9384                -8.5756                -8.0103   \n",
       "4                -8.9953                -8.6287                -8.0473   \n",
       "5                -9.0455                -8.6703                -8.0768   \n",
       "\n",
       "   temperature_100cm [°C]  wind_speed_average [km/h]  net_radiation [Wm^-2]  \\\n",
       "1                 -7.2040                     6.6033              -103.3083   \n",
       "2                 -7.2081                     7.8323              -102.9365   \n",
       "3                 -7.2166                     8.9094              -101.0145   \n",
       "4                 -7.2120                    10.2742              -101.7435   \n",
       "5                 -7.2187                    12.6367              -102.0387   \n",
       "\n",
       "   season  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag = 1\n",
    "diff = temp_inner['temperature_100cm [°C]'] - temp_inner['temperature_5cm [°C]']\n",
    "temp_inner.insert(0, 'delta_t', diff)\n",
    "\n",
    "# shift \n",
    "temp_inner['delta_t'] = temp_inner['delta_t'].shift(lag)\n",
    "temp_inner = temp_inner.drop(temp_inner.index[0 : lag])\n",
    "temp_inner = temp_inner.replace(np.nan, 0)\n",
    "temp_inner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = temp_inner.drop(['delta_t'], axis=1), temp_inner['delta_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation data\n",
    "validation_fraction = 0.2\n",
    "validation_first = False\n",
    "\n",
    "\n",
    "val_size = int(validation_fraction * X.shape[0])\n",
    "train_size = X.shape[0] - val_size\n",
    "\n",
    "if validation_first:\n",
    "    X_train, X_val = Y[val_size:], X[:val_size]\n",
    "    y_train, y_val = y[val_size:], y[:val_size]\n",
    "    \n",
    "else:\n",
    "    X_train, X_val = X[:train_size], X[train_size:]\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data STandartization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_MEAN, Y_STD = y_train.mean(), y_train.std()\n",
    "\n",
    "y_train = (y_train - Y_MEAN)/Y_STD\n",
    "y_val   = (y_val -   Y_MEAN)/Y_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_MEAN, X_STD = X_train.mean(), X_train.std()\n",
    "X_train = (X_train - X_MEAN)/X_STD\n",
    "X_val = (X_val - X_MEAN)/X_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape\n",
    "n_units = 80\n",
    "n_layers = 3\n",
    "n_frames = 5 # length of autoregressive sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "i = layers.Input(shape = (n_frames, 9)) # (?, n_frames, channels) \n",
    "\n",
    "# add the lstm layers\n",
    "x = layers.LSTM(n_units, activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                   return_sequences=True)(i) # (?, n_units)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "n_units *= 2\n",
    "\n",
    "x = layers.LSTM(n_units, activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                   return_sequences=True)(x) # (?, n_units)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "n_units *= 2\n",
    "\n",
    "x = layers.LSTM(n_units, activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                   return_sequences=True)(x) # (?, n_units)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "n_units *= 2\n",
    "\n",
    "x = layers.LSTM(n_units, activation='tanh', recurrent_activation='hard_sigmoid', \n",
    "                   return_sequences=False)(x) # (?, n_units)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "#n_units *= 2            \n",
    "\n",
    "#x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "o = layers.Dense(1, activation = 'linear')(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[i], outputs=[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5, 9)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 80)             28800     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 160)            154240    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 5, 320)            615680    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 640)               2460160   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               82048     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,341,057\n",
      "Trainable params: 3,341,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, losses, metrics\n",
    "    \n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-3),\n",
    "              loss=losses.mse)\n",
    "              #metrics=[metrics.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "class SequenceGenerator(utils.Sequence):\n",
    "    '''Generates image sequences'''\n",
    "\n",
    "    def __init__(self, data, labels, batch_size=32, n_frames=5):\n",
    "        '''Initialization'''\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the number of batches per epoch'''\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generate one batch of data'''\n",
    "\n",
    "        batch_x, batch_y = [], []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            # Get start index of sequence\n",
    "            start_index = np.random.randint(0, len(self.data) - self.n_frames)\n",
    "            stop_index = start_index + self.n_frames\n",
    "\n",
    "            # x = image sequence\n",
    "            x = self.data[start_index:stop_index].values\n",
    "            # y = streamflow at end point\n",
    "            y = self.labels[stop_index]\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SequenceGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-eaa9f81829de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgenerator_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequenceGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgenerator_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequenceGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SequenceGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 120\n",
    "n_epochs = 20\n",
    "generator_train = SequenceGenerator(data = X_train, labels = y_train, batch_size = batch_size, n_frames = n_frames)\n",
    "generator_test = SequenceGenerator(data = X_val, labels = y_val, batch_size = batch_size, n_frames = n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator = generator_train,\n",
    "                              steps_per_epoch = len(X_train)//batch_size,\n",
    "                              epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "y_truth = []\n",
    "for t in range(0, len(X_val)-n_frames):\n",
    "    start_index = t\n",
    "    stop_index = start_index + n_frames\n",
    "    data = X_val[start_index : stop_index].values\n",
    "    data = data[np.newaxis, ...]\n",
    "    p = np.asscalar(model.predict( data))\n",
    "    # p = p * y_std + y_mean\n",
    "    predictions.append(p)\n",
    "    y_truth.append(y_val.iloc[stop_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(y_truth, columns=['True']), \n",
    "           pd.DataFrame(predictions, columns = [\"Predicted\"])], axis = 1).plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
